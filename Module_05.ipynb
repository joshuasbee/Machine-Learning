{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a91ef0e-5eed-4928-96e4-d603d97e3baf"
      },
      "source": [
        "# Note: After you run this cell, the training and test data will be available in\n",
        "# the file browser. (Click the folder icon on the left to view it)\n",
        "#\n",
        "# If you don't see the data after the cell completes, click the refresh button\n",
        "# in the file browser (folder icon with circular arrow)\n",
        "\n",
        "# First, let's download and unzip the data\n",
        "!echo \"Downloading files...\"\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes.csv\n",
        "\n",
        "!echo \"Unzipping files...\"\n",
        "!unzip -q /content/training1.zip\n",
        "!unzip -q /content/training2.zip\n",
        "!unzip -q /content/test.zip\n",
        "\n",
        "# Combine the two traning directories\n",
        "!echo \"Merging training data...\"\n",
        "!mkdir /content/training\n",
        "!mv /content/training1/* /content/training\n",
        "!mv /content/training2/* /content/training\n",
        "\n",
        "# Cleanup\n",
        "!echo \"Cleaning up...\"\n",
        "!rmdir /content/training1\n",
        "!rmdir /content/training2\n",
        "!rm training1.zip\n",
        "!rm training2.zip\n",
        "!rm test.zip\n",
        "\n",
        "!echo \"Data ready.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading files...\n",
            "Unzipping files...\n",
            "Merging training data...\n",
            "Cleaning up...\n",
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9b436f-c7c4-4284-8ac1-a21874753bca"
      },
      "source": [
        "# Create an image training dataset\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# We're using keras' image_dataset_from_directory method to load our image data.\n",
        "# See (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) for details\n",
        "#\n",
        "# A couple of things to note:\n",
        "# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.\n",
        "# 2. Class names are inferred automatically from the image subdirectory names.\n",
        "# 3. We're splitting the training data into 80% training, 20% validation.\n",
        "\n",
        "\n",
        "training_dir = '/content/training/'\n",
        "test_dir = '/content/test'\n",
        "image_size = (100, 100)\n",
        "\n",
        "# Split up the training data images into training and validations sets\n",
        "training_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='training', seed=42, image_size=image_size)\n",
        "validation_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='validation', seed=42, image_size=image_size)\n",
        "# test_data = image_dataset_from_directory(test_dir, seed=42, image_size=image_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39209 files belonging to 43 classes.\n",
            "Using 31368 files for training.\n",
            "Found 39209 files belonging to 43 classes.\n",
            "Using 7841 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# View 9 images and their class labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in training_data.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(training_data.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [
        "# normalize data:\n",
        "from tensorflow.keras import layers\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "#this part makes it so the data can run better, by optimizing memory management or something\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "training_data = training_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_data = validation_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hzrsQdXnCmz"
      },
      "source": [
        "num_classes = 43 #number of signs\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Zim6ElnVNz",
        "outputId": "8fbc47bc-dee4-4722-e172-8e8600561e8b"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  training_data,\n",
        "  validation_data=validation_data,\n",
        "  epochs=10\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "981/981 [==============================] - 35s 35ms/step - loss: 1.8219 - accuracy: 0.4980 - val_loss: 0.2590 - val_accuracy: 0.9272\n",
            "Epoch 2/10\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.1836 - accuracy: 0.9476 - val_loss: 0.0879 - val_accuracy: 0.9788\n",
            "Epoch 3/10\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.1013 - val_accuracy: 0.9754\n",
            "Epoch 4/10\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.1194 - val_accuracy: 0.9716\n",
            "Epoch 5/10\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0441 - accuracy: 0.9874 - val_loss: 0.0672 - val_accuracy: 0.9841\n",
            "Epoch 6/10\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9830\n",
            "Epoch 7/10\n",
            "981/981 [==============================] - 33s 33ms/step - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.1169 - val_accuracy: 0.9736\n",
            "Epoch 8/10\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0317 - accuracy: 0.9921 - val_loss: 0.0578 - val_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "981/981 [==============================] - 32s 32ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0529 - val_accuracy: 0.9909\n",
            "Epoch 10/10\n",
            "981/981 [==============================] - 32s 33ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0731 - val_accuracy: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4192143090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvCxXTSMEeyV"
      },
      "source": [
        "**Testing predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEIQcycLnWW4"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgVZjJfGFGuL"
      },
      "source": [
        "# TEST HOW GOOD THE PREDICTIONS ARE\n",
        "dat = pd.read_csv(\"test/test_classes.csv\")\n",
        "predict_name_list = []\n",
        "per_conf_score_list = []\n",
        "\n",
        "for i in range(len(dat)):\n",
        "  filename = dat.Filename[i]\n",
        "\n",
        "  img = keras.preprocessing.image.load_img(\n",
        "      \"test/\" + filename, target_size=(100,100)\n",
        "  )\n",
        "\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  predict_name_list.append(np.argmax(score))\n",
        "  per_conf_score_list.append((100 * np.max(score)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWYMTwfYMF2Q",
        "outputId": "8c2d822b-5d90-491c-d01b-47b99dcbd335"
      },
      "source": [
        "df = pd.read_csv('/content/test/test_classes.csv')\n",
        "df['guess'] = predict_name_list\n",
        "df['accurate'] = df['ClassId'] == df['guess']\n",
        "sum(df.accurate == True) / len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9429136975455266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAJJM4k_VTnJ"
      },
      "source": [
        "!pip install coremltools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Z6k12VTC_V",
        "outputId": "daef31d9-c6b5-4095-d132-df87545474a4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import coremltools as ct\n",
        "\n",
        "tf_keras_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pass in `tf.keras.Model` to the Unified Conversion API\n",
        "mlmodel = ct.convert(tf_keras_model)\n",
        "mlmodel.save('model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 28.50 passes/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|██████████| 10/10 [00:00<00:00, 811.92 ops/s]\n",
            "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 1460.75 passes/s]\n",
            "Translating MIL ==> MLModel Ops: 100%|██████████| 13/13 [00:00<00:00, 854.53 ops/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOTVo031VkXY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}